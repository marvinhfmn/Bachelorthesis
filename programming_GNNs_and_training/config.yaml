#Folder to save runs to
# basefolder: "/home/saturn/capn/capn108h/programming_GNNs_and_training/runs_and_saved_models(old_datamergedate20240526)"
basefolder: "/home/saturn/capn/capn108h/programming_GNNs_and_training/runs_and_saved_models/"

#Backbone to be used
backbone: DynEdge

#Detector to be used
detector: IceCube86

#clustering and percentiles for node and graph definition 
node_definition:
  cluster_on: [dom_x, dom_y, dom_z, rde, hlc] #[dom_x, dom_y, dom_z] warum kann ich hierauf nicht clustern tf
  percentiles: [0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]

dataloader_config:
  batch_size: 8 #size of one batch
  num_workers: 8 #number of workers for dataloader, should correspond to int(os.environ["SLURM_CPUS_PER_TASK"])

#amount of epochs to be trained for
max_epochs: 15

#amount of epochs that are trained before terminating if there are no improvements in the validation loss, set it to -1 or omit if it shouldn't be used
early_stopping_patience: 3

#accumulate the gradient for k amount of batches before making an optimiser step, set it to -1 or omit if it shouldn't be used
accumulate_grad_batches: 10

#gpus to be used
gpus: -1

#
distribution_strategy: ddp

refresh_rate: 5000

#defining what flavor of neutrinos should be trained on 
flavor: ['NuE', 'NuMu', 'NuTau']
#supported flavors: ['NuE'], ['NuMu'], ['NuTau'] and every combination of the three flavors: 
#['NuE', 'NuMu'], ['NuE', 'NuTau'], ['NuMu', 'NuTau'], ['NuE', 'NuMu', 'NuTau']

#path to the datasets, format: {flavor}_datasetpaths !!

#/home/wecapstor3/capn/capn108h/l2_labeled/merged
#new
NuE_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22612_merged.db', 
                  '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22613_merged.db',
                  '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22614_merged.db']

NuMu_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22644_merged.db', 
                    '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22645_merged.db', 
                    '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22646_merged.db']

NuTau_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22633_merged.db', 
                    '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22634_merged.db', 
                    '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22635_merged.db']

corsikasim_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22615_merged.db']

database_lengths:
  22612: 345900
  22613: 1602308
  22614: 5125665
  22615: 4216310
  22633: 10173744
  22634: 1489233
  22635: 635173
  22644: 305043
  22645: 1714343
  22646: 22151506

#datasets mergedata 12.06
# NuE_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22612_merged.db', 
#                   '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22613_merged.db',
#                   '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22614_merged.db']

# NuMu_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22644_merged.db', 
#                     '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22645_merged.db', 
#                     '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22646_merged.db']

# NuTau_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22633_merged.db', 
#                     '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22634_merged.db', 
#                     '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22635_merged.db']
# 
# corsikasim_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22615_merged.db']

#Include corsika?
use_corsika_bool: False

# if use tmpdir
selection_database_root_folder: '/home/wecapstor3/capn/capn108h/selection_databases/allflavor_classif8_9_19_20_22_23_26_27'

save_database_yaml: False

#parameter to train on (also target label)
training_parameter: ['deposited_energy']
training_parameter_inDatabase: False

#List of event-level columns in the input files that should be used and added as attributes on the graph objects.
addedattributes_trainval: ["first_vertex_energy", "second_vertex_energy", "third_vertex_energy", "visible_track_energy", "visible_spur_energy"]
addedattributes_test: ['classification', 'cosmic_primary_type', 'first_vertex_x', 'first_vertex_y', 'first_vertex_z', 'sim_weight'] #exclusive to test graph
#different to keep the training graph smaller


# training paramter + additional attributes = truth

classifications_to_train_on: [8, 9, 19, 20, 22, 23, 26, 27]

dataset_details:  
  energy_levels:
    'high': [22612, 22644, 22635]
    'mid': [22613, 22645, 22634]
    'low': [22614, 22646, 22633]
  ratios: 
    'high': 1 
    'mid': 4
    'low': 10
  total_events_per_flavor: !!float 1.5e6
  test_size: 0.1



optimizer_kwargs:
  lr: !!float 1e-4 #learning rate
  betas: [0.9, 0.999]
  eps: 0.00000001

scheduler_kwargs:
  patience: 2
  factor: 0.2

scheduler_config:
  frequency: 1
  monitor: "train_loss"

#random state variable, useful to recreate train, val and test datasets (see CustomAdditionsforGNNTraining.CreateCustomDatasets)
random_state: 42

#specify an actual path, no keyword 'last' or 'best' explicitly supported yet 
ckpt_path: '/home/saturn/capn/capn108h/programming_GNNs_and_training/runs_and_saved_models/run_jobid_862299/losses/version_1/checkpoints/DynEdge-epoch=9-val_loss=0.10-train_loss=0.10.ckpt'
