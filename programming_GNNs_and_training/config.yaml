#Folder to save runs to
# basefolder: "/home/saturn/capn/capn108h/programming_GNNs_and_training/runs_and_saved_models(old_datamergedate20240526)"
basefolder: "/home/saturn/capn/capn108h/programming_GNNs_and_training/runs_and_saved_models/"

#Backbone to be used
backbone: DynEdge

#Detector to be used
detector: IceCube86

#clustering and percentiles for node and graph definition 
node_definition:
  cluster_on: [dom_x, dom_y, dom_z]
  percentiles: [10, 20, 30, 40, 50, 60, 70, 80, 90]

dataloader_config:
  batch_size: 8 #size of one batch
  num_workers: 32 #number of workers for dataloader 

#amount of epochs to be trained for
max_epochs: 15

#amount of epochs that are trained before terminating if there are no improvements in the validation loss, set it to -1 or omit if it shouldn't be used
early_stopping_patience: 2

#accumulate the gradient for k amount of batches before making an optimiser step, set it to -1 or omit if it shouldn't be used
accumulate_grad_batches: 5

#gpus to be used
gpus: -1

#defining what flavor of neutrinos should be trained on 
flavor: ['NuE', 'NuMu', 'NuTau']
#supported flavors: ['NuE'], ['NuMu'], ['NuTau'] and every combination of the three flavors: 
#['NuE', 'NuMu'], ['NuE', 'NuTau'], ['NuMu', 'NuTau'], ['NuE', 'NuMu', 'NuTau']

#path to the datasets, format: {flavor}_datasetpaths !!

#/home/wecapstor3/capn/capn108h/l2_labeled/merged
#old
# NuE_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22612_merged.db', 
#                   '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22613_merged.db',
#                   '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22614_merged.db']

# NuMu_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22644_merged.db', 
#                     '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22645_merged.db', 
#                     '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22646_merged.db']

# NuTau_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22633_merged.db', 
#                     '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22634_merged.db', 
#                     '/home/wecapstor3/capn/capn106h/l2_labeled/merged/22635_merged.db']

# corsikasim_datasetpaths: ['/home/wecapstor3/capn/capn106h/l2_labeled/merged/22615_merged.db']

#new datasets
NuE_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22612_merged.db', 
                  '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22613_merged.db',
                  '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22614_merged.db']

NuMu_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22644_merged.db', 
                    '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22645_merged.db', 
                    '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22646_merged.db']

NuTau_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22633_merged.db', 
                    '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22634_merged.db', 
                    '/home/wecapstor3/capn/capn108h/l2_labeled/merged/22635_merged.db']

corsikasim_datasetpaths: ['/home/wecapstor3/capn/capn108h/l2_labeled/merged/22615_merged.db']

#Include corsika?
use_corsika_bool: False 

#parameter to train on (also target label)
training_parameter: ['deposited_energy']
training_parameter_inDatabase: False

#List of event-level columns in the input files that should be used and added as attributes on the graph objects.
addedattributes_trainval: ["first_vertex_energy", "second_vertex_energy", "third_vertex_energy", "visible_track_energy", "visible_spur_energy"]
addedattributes_test: ['cosmic_primary_type', 'first_vertex_x', 'first_vertex_y', 'first_vertex_z', 'sim_weight'] #exclusive to test graph
#different to keep the training graph smaller

classifications_to_train_on: [8, 9, 19, 20, 22, 23, 26, 27]

# training paramter + additional attributes = truth

optimizer_kwargs:
  lr: !!float 1e-4 #learning rate
  betas: [0.9, 0.999]
  eps: 0.00000001

scheduler_kwargs:
  patience: 2
  factor: 0.2

scheduler_config:
  frequency: 1
  monitor: "train_loss"

#random state variable, useful to recreate train, val and test datasets (see CustomAdditionsforGNNTraining.CreateCustomDatasets)
random_state: 42

#specify an actual path, no keyword 'last' or 'best' supported yet 
# ckpt_path: ''